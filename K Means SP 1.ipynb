{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "451cbaee",
   "metadata": {},
   "source": [
    "# K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d48e010",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeadace",
   "metadata": {},
   "source": [
    "The k-means type\n",
    "clustering algorithms are widely used in real world\n",
    "applications such as marketing research and data mining\n",
    "to cluster very large data sets due to their efficiency and\n",
    "ability to handle numeric and categorical variables that are\n",
    "ubiquitous in real databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96a8cf1",
   "metadata": {},
   "source": [
    " ## 2. The Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d535c032",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "  \n",
    "\n",
    "Let $X= \\{ X_{1}, \\ X_2,...,\\ X_n \\}$ be a set of $n$ objects. Object $X_i= \\{ x_{i,1}, \\ x_{i,2},...,\\ x_{i,m}\\}$ is characterized by a set of $m$ variables. We want to partition the $n$ objects into $k$ clusters that minimizes the objective function $P$ with unknown variables $U$ and $Z$ as follows: $$  P(U,Z)= \\sum_{l=1}^{k}\\sum_{i=1}^{n}\\sum_{j=1}^{m} u_{i,l}  d(x_{i,j}, z_{l,j})  $$ where,  \n",
    "- $U$ is an $n \\times k$ partition matrix, $u_{i,l}$ is a binary variable, and $u_{i,l}=1$ indicates that object $i$ is allocated to cluster $l$;  \n",
    "- $Z= \\{ Z_{1}, \\ Z_2,...,\\ Z_k \\}$ is a set of $k$ vectors representing the centroids of the $k$ clusters;   \n",
    "- $d(x_{i,j}, z_{l,j}) $ is a distance measure between object $i$ and the centroid of the cluster $l$ on the $j$th variable. We define here $d(x_{i,j}, z_{l,j}) $ as : $$d(x_{i,j}, z_{l,j})= (x_{i,j}-z_{l,j})^{2}.$$   \n",
    "\n",
    "So to minimize the cost function $P$, we have the K-means clustering as follows:  \n",
    "\n",
    "**K-means Algorithm**    \n",
    "1. Randomly choose an initial set of centroids $Z^{0}=\\{Z_{1},Z_{2},...,Z_{k}\\}$. Determine $U^{0}$ such that $P(U^{0},Z^{0},W^{0})$ is minimized. Set $t=0$ ;   \n",
    "2. Let $\\hat{Z}=Z^{t}$, now solve the reduced problem $P(U,\\hat{Z})$ to obtain $U^{t+1}$. If $P(U^{t+1},\\hat{Z})=P(U^{t},\\hat{Z})$, output $(U^{t},\\hat{Z})$ and stop; otherwise go to step 2;   \n",
    "3. Let $\\hat{U}=U^{t+1}$ , now solve the reduced problem $P(\\hat{U},Z)$ to obtain $Z^{t+1}$. If $P(\\hat{U},Z^{t+1})=P(\\hat{U},Z^{t})$, output $(\\hat{U},Z^{t})$ and stop; otherwise set $t=t+1$ go to step 2.   \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96eeecaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install colorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "104c0b60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59563bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from colorama import Fore, Back, Style\n",
    "from IPython.display import Markdown, display\n",
    "from matplotlib import pyplot as plt\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "    \n",
    "def np_ed(point_1, point_2):\n",
    "    distance = np.sum(np.square(np.array(point_1) - np.array(point_2)))\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584f2220",
   "metadata": {},
   "source": [
    "## 3. Defining the K-Means Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abb6a80",
   "metadata": {},
   "source": [
    "### 3.1 Initializing the first centroids and determining $T$ by minimizing $P$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99495f9",
   "metadata": {},
   "source": [
    "As the 1st step of the Weighted K Means clustering we initialize the centroid vector and randomly generate the set of initial weights. Then we determine the clusters for each data points in the first iteration.   \n",
    "**Replacing $U$ by $T$**   \n",
    "In the original paper, to denote the clusters for each data point in every iteration, the $n \\times k$ matrix $U$ was used. The elements $u_{i,l}$ of $U$ is a binary variable, and $u_{i,l}=1$ indicates that object $i$ is allocated to cluster $l$. For brevity and ease, I use a different variable $T$ which is a $(n \\times 1)$ column vector, each element of $T$ is a number from the set $\\{1,2,...,k\\}$ and $t_{i,1}=l$ ,$(l \\in \\ \\{1,2,...,k\\})$, means that the $i$th data point belongs to the $l$th cluster. So rewriting our cost function $P$ in terms of $T$, $$  P(T,Z)= \\sum_{l=1}^{k}\\sum_{i=1}^{n}\\sum_{j=1}^{m} \\mathbb{1}(t_{i,1}=l) d(x_{i,j}, z_{l,j})  $$ where $\\mathbb{1}$ is the indicator function defined as \n",
    "$$\\begin{equation}\n",
    "\\mathbb{1}(t_{i,1}=l) =\n",
    "    \\begin{cases}\n",
    "        1 & \\text{if the $i$th data point belongs to the $l$th cluster} \\\\\n",
    "        0 & \\text{otherwise}\n",
    "    \\end{cases}\n",
    "\\end{equation}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3862a3a",
   "metadata": {},
   "source": [
    "### 3.2 Iteration step for the centroids "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f1f851",
   "metadata": {},
   "source": [
    "Now we implement the K-means clustering. We carry the three steps until the cost function $P$ becomes constant. In the 2nd step of the K-means clustering, using the $Z$ of the previous iteration we solve for the $T$ that minimizes the cost function $P$. In the following code, after every iteration for the number of data points that belong to each cluster, we get the matrix $T$, the number of data points in each cluster in that iteration and the value of $P$ as output.   \n",
    "In the 3rd step of the K-means clustering, using the $T$ of the previous iteration we solve for the $Z$ that minimizes the cost function $P$. Solving for $Z$, we get that $P$ is minimized when $$z_{l,j}= \\frac{\\sum_{i=1}^{n} \\mathbb{1}(t_{i,1}=l)\\ x_{i,j}}{\\sum_{i=1}^{n} \\mathbb{1}(t_{i,1}=l)}$$where $1 \\le l \\le k$ and $0 \\le j \\le m$.  The following code gives us the new centroids and the value of $P$.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e043fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.30029201   5.57762667]\n",
      " [  7.29691436   3.21136253]\n",
      " [-10.59698143  -2.68536417]\n",
      " ...\n",
      " [  4.95514709  12.59525492]\n",
      " [  2.11705948  13.96820765]\n",
      " [ -2.24138468  15.58603699]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import genfromtxt\n",
    "D1= genfromtxt(\"C:/Users/Deepam Saha/OneDrive/Desktop/Deepam.csv\",delimiter=\",\")\n",
    "D= np.delete(D1,0,0)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92724d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(X, k, max_iter=100, tol=1e-6):\n",
    "    P=0\n",
    "    q=1\n",
    "    A=np.random.choice(X.shape[0], k, replace=False)\n",
    "    print(A)\n",
    "    Z = np.array(X[A]) \n",
    "    \n",
    "        \n",
    "    for o in range(max_iter):\n",
    "        T=np.zeros(X.shape[0])\n",
    "        P1=P\n",
    "        P=0\n",
    "        ed=np.zeros((X.shape[0],k))\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(k):\n",
    "                ed[i][j] = np_ed(Z[j], X[i])\n",
    "        np.T = np.argmin(ed, axis=1)\n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            P =  P + np_ed(X[i], Z[np.T[i]])\n",
    "            \n",
    "        print(Fore.LIGHTBLUE_EX,\"The new clusters for the\",q,\"th iteration\")    \n",
    "        printmd(\"**The Matrix T :**\")\n",
    "        print(np.T)\n",
    "\n",
    "        for l in range(k):\n",
    "            print(\"No. of data points in\", l+1, \"cluster:\")\n",
    "            print(np.count_nonzero(np.T == l))\n",
    "        \n",
    "        printmd(\"**Value of P:**\")\n",
    "        \n",
    "        print(P,\"\\n\")\n",
    "        if (P1==P): \n",
    "            break\n",
    "        \n",
    "        P1=P\n",
    "        P=0\n",
    "        for j in range(k):\n",
    "            Z[j]= np.sum(X[np.T==j],axis=0)/np.count_nonzero(np.T == j)\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "             P=  P + np_ed(X[i], Z[np.T[i]])\n",
    "           \n",
    "        print(Fore.LIGHTBLUE_EX,\"The new centroids for the\",q,\"th iteration\")  \n",
    "        printmd(\"**Centroids:**\")\n",
    "        print(Z)                                                     #The new clusters in this iteration\n",
    "        plt.scatter(X[np.T == 0, 0], X[np.T == 0, 1], s = 100, c = 'purple', label = 'N1')\n",
    "        plt.scatter(X[np.T == 1, 0], X[np.T == 1, 1], s = 100, c = 'orange', label = 'N2')\n",
    "        plt.scatter(X[np.T == 2, 0], X[np.T == 2, 1], s = 100, c = 'green', label = 'N3')\n",
    "  #      plt.scatter(X[np.T == 3, 0], X[np.T == 3, 1], s = 100, c = 'blue', label = 'N4')\n",
    "        plt.scatter(Z[:, 0], Z[:,1], s = 100, c = 'red', label = 'Centroids')\n",
    "        plt.show()\n",
    "        printmd(\"**Value of P:**\")\n",
    "        print(P,\"\\n\")\n",
    "        if (P1==P): \n",
    "            break\n",
    "        q=q+1\n",
    "    print(Fore.LIGHTMAGENTA_EX,\"The number of iterations:\",q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfba8417",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmeans(D,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8e0c73",
   "metadata": {},
   "source": [
    "iris=pd.read_csv (\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\",\n",
    "                   names = [\"Sepal Length\", \"Sepal Width\", \"Petal Length\", \"Petal Width\", \"Class\" ])  #Reading the csv file\n",
    "X1 = iris.iloc[:,0:4]\n",
    "y = iris.iloc[:,-1]\n",
    "X=np.array(X1)\n",
    "kmeans(X,3)\n",
    "print(X)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
